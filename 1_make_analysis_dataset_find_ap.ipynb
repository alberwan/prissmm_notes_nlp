{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to make analysis datasets. Code cells containing PHI have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data folder (would need to be changed to run in another context)\n",
    "datafolder = '/data/clin_notes_outcomes/prissmm_notes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in the EHR text data for all patients in the cohort (82268 is OncDRS request ID number)\n",
    "raw_notes = pd.read_parquet(datafolder+'parsed_82268.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6526673 entries, 0 to 6526672\n",
      "Data columns (total 7 columns):\n",
      "dfci_mrn         object\n",
      "date             datetime64[ns]\n",
      "text             object\n",
      "source           object\n",
      "department       object\n",
      "provider_name    object\n",
      "report_type      object\n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 348.6+ MB\n",
      "None\n",
      "Progress Note             1150740\n",
      "Imaging                    964671\n",
      "Lab                        499946\n",
      "Telephone Encounter        311429\n",
      "Pathology and Cytology     290885\n",
      "                           ...   \n",
      "QUESTIONNAIRE                   3\n",
      "AUTOPSY NOTE                    3\n",
      "EDUCATION                       2\n",
      "Group Note                      1\n",
      "REVIEW OF SYSTEMS               1\n",
      "Name: report_type, Length: 92, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(raw_notes.info())\n",
    "print(raw_notes.report_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = raw_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1354217 entries, 0 to 6526665\n",
      "Data columns (total 7 columns):\n",
      "dfci_mrn         1354217 non-null int64\n",
      "date             1354217 non-null datetime64[ns]\n",
      "text             1354217 non-null object\n",
      "source           1354217 non-null object\n",
      "department       1288191 non-null object\n",
      "provider_name    1354217 non-null object\n",
      "report_type      1354217 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 82.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# keep notes corresponding to progress note categories\n",
    "all_notes = all_notes[all_notes.report_type.isin([\"Progress Note\", \"PROGRESS NOTE\", \"CONSULT\", \"CONSULTATION NOTE\", \"VISIT NOTE\", \"COMPREHENSIVE H&P\"])]\n",
    "\n",
    "all_notes = all_notes[~all_notes.provider_name.isnull()]\n",
    "all_notes.dfci_mrn = pd.to_numeric(all_notes.dfci_mrn)\n",
    "\n",
    "all_notes.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to split notes into pre-assessment and plan and post-assessment and plan sections (using rules)\n",
    "\n",
    "def find_ap(string):\n",
    "    ap_search_phrase = \"a/p|assessment/plan|assessment:|assessment and plan|impression and plan|in summary|plan:\"\n",
    "    splitup = re.split(ap_search_phrase, string)\n",
    "    if len(splitup) < 2:\n",
    "        return splitup + ['']\n",
    "    else:\n",
    "        return [splitup[0]] + [\" \".join(splitup[1:])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello world. ', ': progression of disease.   progression']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test rules function\n",
    "\n",
    "import re\n",
    "find_ap(\"hello world. assessment and plan: progression of disease. assessment: progression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1354217 entries, 0 to 6526665\n",
      "Data columns (total 7 columns):\n",
      "dfci_mrn         1354217 non-null int64\n",
      "date             1354217 non-null datetime64[ns]\n",
      "text             1354217 non-null object\n",
      "source           1354217 non-null object\n",
      "department       1288191 non-null object\n",
      "provider_name    1354217 non-null object\n",
      "report_type      1354217 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 82.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove carriage returns and make all text lowercase\n",
    "all_notes.text = all_notes.text.str.replace('\\n|\\r', ' ')\n",
    "all_notes.text = all_notes.text.str.lower()\n",
    "all_notes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1354217\n",
       "Name: dfci_mrn, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure all notes have a valid patient ID\n",
    "all_notes.dfci_mrn.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27274 entries, 0 to 27273\n",
      "Data columns (total 2 columns):\n",
      "Unnamed: 0    27274 non-null int64\n",
      "dfci_mrn      27274 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 426.3 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1083879,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in list of patients previously assigned to a training set\n",
    "\n",
    "vocab_size = 10000\n",
    "training_mrns = pd.read_csv(datafolder + 'training_mrns_76525_82268.csv')\n",
    "training_mrns.info()\n",
    "train_text = all_notes[all_notes.dfci_mrn.isin(training_mrns.dfci_mrn)].text\n",
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TF/Keras tokenizer vocabulray using training set notes\n",
    "\n",
    "train_tokenizer = True\n",
    "\n",
    "if train_tokenizer:\n",
    "    tokenizer = Tokenizer(num_words = vocab_size)\n",
    "    tokenizer.fit_on_texts([str(x) for x in train_text])\n",
    "    with open('/homes10/klkehl/prissmm_notes_v2/notes_tokenizer_ap_find.pickle', 'wb') as handle:\n",
    "         pickle.dump(tokenizer, handle, protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/homes10/klkehl/prissmm_notes_v2/notes_tokenizer_ap_find.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = [find_ap(x) for x in all_notes.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes = all_notes[['dfci_mrn', 'date', 'source', 'department', 'provider_name', 'report_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text into pre and post assessment and plan sections\n",
    "\n",
    "all_notes['pre_ap'] = [x[0] for x in split_text]\n",
    "all_notes['ap'] = [x[1] for x in split_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mrns = pd.read_csv(datafolder + 'training_mrns_76525_82268.csv')\n",
    "validation_mrns = pd.read_csv(datafolder + 'validation_mrns_76525_82268.csv')\n",
    "true_test_mrns = pd.read_csv(datafolder + 'truetest_mrns_76525_82268.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083879\n"
     ]
    }
   ],
   "source": [
    "# how many notes are there in the training set?\n",
    "training = pd.merge(all_notes, training_mrns, on='dfci_mrn')\n",
    "validation = pd.merge(all_notes, validation_mrns, on='dfci_mrn')\n",
    "test = pd.merge(all_notes, true_test_mrns, on='dfci_mrn')\n",
    "print(len(training.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output datasets\n",
    "training.to_parquet(datafolder+'training_notes_find_ap.parquet')\n",
    "validation.to_parquet(datafolder+'validation_notes_find_ap.parquet')\n",
    "test.to_parquet(datafolder+'test_notes_find_ap.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
